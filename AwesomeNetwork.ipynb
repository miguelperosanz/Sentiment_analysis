{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AwesomeNetwork.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7aSMF-HWWKJ",
        "colab_type": "text"
      },
      "source": [
        "#**LOAD BTC DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5uX2UlbmNc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "execution_count": 394,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NKuHQHLOZ8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "data = pd.read_csv('BTC-USD.csv',index_col = 0,parse_dates = True, na_values = 0).dropna()\n",
        "\n",
        "data = data[:data.shape[0]-60] # To cut the data and try earlier test timeframes\n"
      ],
      "execution_count": 395,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctuNdvv6OkjY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "d3d05d73-06a6-4b65-9e69-aeb7460a0f6c"
      },
      "source": [
        "data.tail()"
      ],
      "execution_count": 396,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-04-10</th>\n",
              "      <td>7303.815430</td>\n",
              "      <td>7303.815430</td>\n",
              "      <td>6802.475098</td>\n",
              "      <td>6865.493164</td>\n",
              "      <td>6865.493164</td>\n",
              "      <td>4.362284e+10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-11</th>\n",
              "      <td>6867.440430</td>\n",
              "      <td>6926.069824</td>\n",
              "      <td>6789.920898</td>\n",
              "      <td>6859.083008</td>\n",
              "      <td>6859.083008</td>\n",
              "      <td>3.122209e+10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-12</th>\n",
              "      <td>6858.067871</td>\n",
              "      <td>7119.947266</td>\n",
              "      <td>6811.078125</td>\n",
              "      <td>6971.091797</td>\n",
              "      <td>6971.091797</td>\n",
              "      <td>3.575957e+10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-13</th>\n",
              "      <td>6965.616699</td>\n",
              "      <td>6965.616699</td>\n",
              "      <td>6668.259766</td>\n",
              "      <td>6845.037598</td>\n",
              "      <td>6845.037598</td>\n",
              "      <td>3.861931e+10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-14</th>\n",
              "      <td>6843.281738</td>\n",
              "      <td>6958.557129</td>\n",
              "      <td>6793.821289</td>\n",
              "      <td>6842.427734</td>\n",
              "      <td>6842.427734</td>\n",
              "      <td>3.411043e+10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Open         High  ...    Adj Close        Volume\n",
              "Date                                  ...                           \n",
              "2020-04-10  7303.815430  7303.815430  ...  6865.493164  4.362284e+10\n",
              "2020-04-11  6867.440430  6926.069824  ...  6859.083008  3.122209e+10\n",
              "2020-04-12  6858.067871  7119.947266  ...  6971.091797  3.575957e+10\n",
              "2020-04-13  6965.616699  6965.616699  ...  6845.037598  3.861931e+10\n",
              "2020-04-14  6843.281738  6958.557129  ...  6842.427734  3.411043e+10\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 396
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLVMUpmgWxCx",
        "colab_type": "text"
      },
      "source": [
        "#**DATA SCALING**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZtS1lwSljwl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "b4a2171a-e127-484c-a905-50da61eacb11"
      },
      "source": [
        "max_=data[['Open','High','Low','Close']].max().max()\n",
        "min_=data[['Open','High','Low','Close']].min().min()\n",
        "\n",
        "scl=MinMaxScaler()\n",
        "\n",
        "X1=(data[['Open','High','Low','Close']]-min_)/(max_-min_)\n",
        "X2=scl.fit_transform(data[['Volume']].values.reshape(-1,1))\n",
        "X1=np.array(X1)\n",
        "\n",
        "data=data.assign(Open=X1[:,0])\n",
        "data=data.assign(High=X1[:,1])\n",
        "data=data.assign(Low=X1[:,2])\n",
        "data=data.assign(Close=X1[:,3])\n",
        "data=data.assign(Volume=X2[:,0])\n",
        "data.tail()"
      ],
      "execution_count": 397,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-04-10</th>\n",
              "      <td>0.358093</td>\n",
              "      <td>0.358093</td>\n",
              "      <td>0.332922</td>\n",
              "      <td>0.336086</td>\n",
              "      <td>6865.493164</td>\n",
              "      <td>0.588219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-11</th>\n",
              "      <td>0.336183</td>\n",
              "      <td>0.339127</td>\n",
              "      <td>0.332291</td>\n",
              "      <td>0.335764</td>\n",
              "      <td>6859.083008</td>\n",
              "      <td>0.420982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-12</th>\n",
              "      <td>0.335713</td>\n",
              "      <td>0.348861</td>\n",
              "      <td>0.333354</td>\n",
              "      <td>0.341387</td>\n",
              "      <td>6971.091797</td>\n",
              "      <td>0.482175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-13</th>\n",
              "      <td>0.341113</td>\n",
              "      <td>0.341113</td>\n",
              "      <td>0.326183</td>\n",
              "      <td>0.335059</td>\n",
              "      <td>6845.037598</td>\n",
              "      <td>0.520741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-14</th>\n",
              "      <td>0.334971</td>\n",
              "      <td>0.340758</td>\n",
              "      <td>0.332487</td>\n",
              "      <td>0.334928</td>\n",
              "      <td>6842.427734</td>\n",
              "      <td>0.459934</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Open      High       Low     Close    Adj Close    Volume\n",
              "Date                                                                     \n",
              "2020-04-10  0.358093  0.358093  0.332922  0.336086  6865.493164  0.588219\n",
              "2020-04-11  0.336183  0.339127  0.332291  0.335764  6859.083008  0.420982\n",
              "2020-04-12  0.335713  0.348861  0.333354  0.341387  6971.091797  0.482175\n",
              "2020-04-13  0.341113  0.341113  0.326183  0.335059  6845.037598  0.520741\n",
              "2020-04-14  0.334971  0.340758  0.332487  0.334928  6842.427734  0.459934"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 397
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBQJLe2BUNZ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "daabd8f2-86a3-462f-8d84-0f781a481ffb"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 398,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2037, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 398
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIpgXQegXeKI",
        "colab_type": "text"
      },
      "source": [
        "#**DEFINE INPUTS AND TARGET FEATURES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o5B_2w4Own0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "87e3011c-cf13-4c8f-e58e-591766ffb51e"
      },
      "source": [
        "X=data[['Open','High','Low','Close','Volume']]\n",
        "y=data.Close.shift(-1)\n",
        "X.tail()"
      ],
      "execution_count": 399,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-04-10</th>\n",
              "      <td>0.358093</td>\n",
              "      <td>0.358093</td>\n",
              "      <td>0.332922</td>\n",
              "      <td>0.336086</td>\n",
              "      <td>0.588219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-11</th>\n",
              "      <td>0.336183</td>\n",
              "      <td>0.339127</td>\n",
              "      <td>0.332291</td>\n",
              "      <td>0.335764</td>\n",
              "      <td>0.420982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-12</th>\n",
              "      <td>0.335713</td>\n",
              "      <td>0.348861</td>\n",
              "      <td>0.333354</td>\n",
              "      <td>0.341387</td>\n",
              "      <td>0.482175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-13</th>\n",
              "      <td>0.341113</td>\n",
              "      <td>0.341113</td>\n",
              "      <td>0.326183</td>\n",
              "      <td>0.335059</td>\n",
              "      <td>0.520741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-14</th>\n",
              "      <td>0.334971</td>\n",
              "      <td>0.340758</td>\n",
              "      <td>0.332487</td>\n",
              "      <td>0.334928</td>\n",
              "      <td>0.459934</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Open      High       Low     Close    Volume\n",
              "Date                                                        \n",
              "2020-04-10  0.358093  0.358093  0.332922  0.336086  0.588219\n",
              "2020-04-11  0.336183  0.339127  0.332291  0.335764  0.420982\n",
              "2020-04-12  0.335713  0.348861  0.333354  0.341387  0.482175\n",
              "2020-04-13  0.341113  0.341113  0.326183  0.335059  0.520741\n",
              "2020-04-14  0.334971  0.340758  0.332487  0.334928  0.459934"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 399
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLpkTtMfO24G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "587957f4-d9d7-4d76-fe72-d99ce588960f"
      },
      "source": [
        "timestep=10\n",
        "X_list=[]\n",
        "y_list=[]\n",
        "for i in range(timestep,len(X)):\n",
        "    X_list.append(np.array(X.iloc[i-timestep:i]))\n",
        "    y_list.append(y.iloc[i])\n",
        "\n",
        "test_size=60\n",
        "X_train=np.array(X_list)[:-test_size]\n",
        "y_train=np.array(y_list)[:-test_size]\n",
        "X_test=np.array(X_list)[-test_size:]\n",
        "y_test=np.array(y_list)[-test_size:]\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": 400,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1967, 10, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 400
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YVnNBWrXvdV",
        "colab_type": "text"
      },
      "source": [
        "#**CREATE RNN MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFAdvuXmO5En",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "outputId": "ed6c29bc-9835-430d-d976-fa49f5d74809"
      },
      "source": [
        "from keras.layers import SimpleRNN\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "dropout_ratio=0.5\n",
        "model=Sequential()\n",
        "model.add(SimpleRNN(timestep,input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dense(32))\n",
        "model.add(Dropout(dropout_ratio))\n",
        "model.add(Dense(64))\n",
        "model.add(Dropout(dropout_ratio))\n",
        "model.add(Dense(128))\n",
        "model.add(Dropout(dropout_ratio))\n",
        "model.add(Dense(256))\n",
        "model.add(Dropout(dropout_ratio))\n",
        "model.add(Dense(512))\n",
        "model.add(Dropout(dropout_ratio))\n",
        "model.add(Dense(1024))\n",
        "model.add(Dropout(dropout_ratio))\n",
        "model.add(Dense(2048))\n",
        "model.add(Dropout(dropout_ratio))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', \n",
        "              optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": 401,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_18 (SimpleRNN)    (None, 10)                160       \n",
            "_________________________________________________________________\n",
            "dense_144 (Dense)            (None, 32)                352       \n",
            "_________________________________________________________________\n",
            "dropout_126 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_145 (Dense)            (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_127 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_146 (Dense)            (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dropout_128 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_147 (Dense)            (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dropout_129 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_148 (Dense)            (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_130 (Dropout)        (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_149 (Dense)            (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dropout_131 (Dropout)        (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_150 (Dense)            (None, 2048)              2099200   \n",
            "_________________________________________________________________\n",
            "dropout_132 (Dropout)        (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_151 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 2,802,113\n",
            "Trainable params: 2,802,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzB-43prYAo2",
        "colab_type": "text"
      },
      "source": [
        "#**FIT MODEL AND SAVE BEST WEIGHTS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmzzATaDPBhe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0414acf1-516b-4c04-95cf-3c165818a3fa"
      },
      "source": [
        "filepath=\"weights-btc.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "history = model.fit(X_train, y_train, epochs=200, batch_size=50, verbose=1, validation_split=0.2, callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 3.6294\n",
            "Epoch 00001: val_loss improved from inf to 1.98980, saving model to weights-btc.hdf5\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 3.6137 - val_loss: 1.9898\n",
            "Epoch 2/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.8551\n",
            "Epoch 00002: val_loss improved from 1.98980 to 0.05363, saving model to weights-btc.hdf5\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.8463 - val_loss: 0.0536\n",
            "Epoch 3/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.2549\n",
            "Epoch 00003: val_loss did not improve from 0.05363\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.2532 - val_loss: 0.0660\n",
            "Epoch 4/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1142\n",
            "Epoch 00004: val_loss improved from 0.05363 to 0.00403, saving model to weights-btc.hdf5\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.1142 - val_loss: 0.0040\n",
            "Epoch 5/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0746\n",
            "Epoch 00005: val_loss did not improve from 0.00403\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0740 - val_loss: 0.0193\n",
            "Epoch 6/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0564\n",
            "Epoch 00006: val_loss did not improve from 0.00403\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0563 - val_loss: 0.0064\n",
            "Epoch 7/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0500\n",
            "Epoch 00007: val_loss improved from 0.00403 to 0.00316, saving model to weights-btc.hdf5\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0500 - val_loss: 0.0032\n",
            "Epoch 8/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0510\n",
            "Epoch 00008: val_loss did not improve from 0.00316\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0508 - val_loss: 0.0044\n",
            "Epoch 9/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0426\n",
            "Epoch 00009: val_loss did not improve from 0.00316\n",
            "32/32 [==============================] - 2s 57ms/step - loss: 0.0427 - val_loss: 0.0087\n",
            "Epoch 10/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0382\n",
            "Epoch 00010: val_loss did not improve from 0.00316\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0378 - val_loss: 0.0034\n",
            "Epoch 11/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0356\n",
            "Epoch 00011: val_loss improved from 0.00316 to 0.00179, saving model to weights-btc.hdf5\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0360 - val_loss: 0.0018\n",
            "Epoch 12/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0342\n",
            "Epoch 00012: val_loss improved from 0.00179 to 0.00173, saving model to weights-btc.hdf5\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0343 - val_loss: 0.0017\n",
            "Epoch 13/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0336\n",
            "Epoch 00013: val_loss did not improve from 0.00173\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0334 - val_loss: 0.0041\n",
            "Epoch 14/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0293\n",
            "Epoch 00014: val_loss did not improve from 0.00173\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0291 - val_loss: 0.0062\n",
            "Epoch 15/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0249\n",
            "Epoch 00015: val_loss did not improve from 0.00173\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0248 - val_loss: 0.0058\n",
            "Epoch 16/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0289\n",
            "Epoch 00016: val_loss did not improve from 0.00173\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0286 - val_loss: 0.0021\n",
            "Epoch 17/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0236\n",
            "Epoch 00017: val_loss did not improve from 0.00173\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0235 - val_loss: 0.0031\n",
            "Epoch 18/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0210\n",
            "Epoch 00018: val_loss improved from 0.00173 to 0.00131, saving model to weights-btc.hdf5\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.0209 - val_loss: 0.0013\n",
            "Epoch 19/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0224\n",
            "Epoch 00019: val_loss did not improve from 0.00131\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.0227 - val_loss: 0.0017\n",
            "Epoch 20/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0205\n",
            "Epoch 00020: val_loss did not improve from 0.00131\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0203 - val_loss: 0.0016\n",
            "Epoch 21/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0202\n",
            "Epoch 00021: val_loss did not improve from 0.00131\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0200 - val_loss: 0.0027\n",
            "Epoch 22/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0220\n",
            "Epoch 00022: val_loss did not improve from 0.00131\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0220 - val_loss: 0.0019\n",
            "Epoch 23/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0198\n",
            "Epoch 00023: val_loss did not improve from 0.00131\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0196 - val_loss: 0.0072\n",
            "Epoch 24/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0211\n",
            "Epoch 00024: val_loss did not improve from 0.00131\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0212 - val_loss: 0.0015\n",
            "Epoch 25/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0190\n",
            "Epoch 00025: val_loss did not improve from 0.00131\n",
            "32/32 [==============================] - 2s 57ms/step - loss: 0.0190 - val_loss: 0.0069\n",
            "Epoch 26/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0174\n",
            "Epoch 00026: val_loss improved from 0.00131 to 0.00125, saving model to weights-btc.hdf5\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0173 - val_loss: 0.0013\n",
            "Epoch 27/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0190\n",
            "Epoch 00027: val_loss improved from 0.00125 to 0.00121, saving model to weights-btc.hdf5\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0191 - val_loss: 0.0012\n",
            "Epoch 28/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0199\n",
            "Epoch 00028: val_loss did not improve from 0.00121\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0200 - val_loss: 0.0038\n",
            "Epoch 29/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0171\n",
            "Epoch 00029: val_loss did not improve from 0.00121\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0172 - val_loss: 0.0038\n",
            "Epoch 30/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0153\n",
            "Epoch 00030: val_loss improved from 0.00121 to 0.00101, saving model to weights-btc.hdf5\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.0153 - val_loss: 0.0010\n",
            "Epoch 31/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0211\n",
            "Epoch 00031: val_loss did not improve from 0.00101\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0209 - val_loss: 0.0039\n",
            "Epoch 32/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0190\n",
            "Epoch 00032: val_loss did not improve from 0.00101\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0194 - val_loss: 0.0022\n",
            "Epoch 33/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0164\n",
            "Epoch 00033: val_loss did not improve from 0.00101\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0167 - val_loss: 0.0024\n",
            "Epoch 34/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0158\n",
            "Epoch 00034: val_loss did not improve from 0.00101\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0159 - val_loss: 0.0016\n",
            "Epoch 35/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0162\n",
            "Epoch 00035: val_loss did not improve from 0.00101\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0162 - val_loss: 0.0012\n",
            "Epoch 36/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0166\n",
            "Epoch 00036: val_loss did not improve from 0.00101\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0166 - val_loss: 0.0018\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0171\n",
            "Epoch 00037: val_loss did not improve from 0.00101\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0171 - val_loss: 0.0014\n",
            "Epoch 38/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0157\n",
            "Epoch 00038: val_loss did not improve from 0.00101\n",
            "32/32 [==============================] - 2s 57ms/step - loss: 0.0161 - val_loss: 0.0057\n",
            "Epoch 39/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0149\n",
            "Epoch 00039: val_loss did not improve from 0.00101\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0147 - val_loss: 0.0050\n",
            "Epoch 40/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0145\n",
            "Epoch 00040: val_loss did not improve from 0.00101\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0147 - val_loss: 0.0030\n",
            "Epoch 41/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0152\n",
            "Epoch 00041: val_loss did not improve from 0.00101\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0154 - val_loss: 0.0013\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0133\n",
            "Epoch 00042: val_loss did not improve from 0.00101\n",
            "32/32 [==============================] - 2s 56ms/step - loss: 0.0133 - val_loss: 0.0025\n",
            "Epoch 43/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0137\n",
            "Epoch 00043: val_loss did not improve from 0.00101\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0138 - val_loss: 0.0012\n",
            "Epoch 44/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0146\n",
            "Epoch 00044: val_loss did not improve from 0.00101\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0145 - val_loss: 0.0026\n",
            "Epoch 45/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0148\n",
            "Epoch 00045: val_loss did not improve from 0.00101\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0147 - val_loss: 0.0013\n",
            "Epoch 46/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0145\n",
            "Epoch 00046: val_loss did not improve from 0.00101\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0144 - val_loss: 0.0036\n",
            "Epoch 47/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0131\n",
            "Epoch 00047: val_loss did not improve from 0.00101\n",
            "32/32 [==============================] - 2s 56ms/step - loss: 0.0130 - val_loss: 0.0023\n",
            "Epoch 48/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0119\n",
            "Epoch 00048: val_loss did not improve from 0.00101\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0120 - val_loss: 0.0044\n",
            "Epoch 49/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0114\n",
            "Epoch 00049: val_loss did not improve from 0.00101\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0113 - val_loss: 0.0016\n",
            "Epoch 50/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0111\n",
            "Epoch 00050: val_loss did not improve from 0.00101\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0111 - val_loss: 0.0011\n",
            "Epoch 51/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0116\n",
            "Epoch 00051: val_loss did not improve from 0.00101\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0115 - val_loss: 0.0066\n",
            "Epoch 52/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0124\n",
            "Epoch 00052: val_loss improved from 0.00101 to 0.00093, saving model to weights-btc.hdf5\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0123 - val_loss: 9.3363e-04\n",
            "Epoch 53/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0103\n",
            "Epoch 00053: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0103 - val_loss: 0.0032\n",
            "Epoch 54/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0108\n",
            "Epoch 00054: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0107 - val_loss: 0.0050\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0108\n",
            "Epoch 00055: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 56ms/step - loss: 0.0108 - val_loss: 0.0010\n",
            "Epoch 56/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0107\n",
            "Epoch 00056: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0108 - val_loss: 0.0024\n",
            "Epoch 57/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0099\n",
            "Epoch 00057: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0098 - val_loss: 0.0014\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0112\n",
            "Epoch 00058: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.0112 - val_loss: 0.0012\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0094\n",
            "Epoch 00059: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 3s 83ms/step - loss: 0.0094 - val_loss: 0.0059\n",
            "Epoch 60/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0116\n",
            "Epoch 00060: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 56ms/step - loss: 0.0114 - val_loss: 0.0014\n",
            "Epoch 61/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0101\n",
            "Epoch 00061: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 48ms/step - loss: 0.0101 - val_loss: 0.0058\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0104\n",
            "Epoch 00062: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 1s 47ms/step - loss: 0.0104 - val_loss: 0.0026\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0093\n",
            "Epoch 00063: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 47ms/step - loss: 0.0093 - val_loss: 0.0023\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0095\n",
            "Epoch 00064: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 47ms/step - loss: 0.0095 - val_loss: 0.0036\n",
            "Epoch 65/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0098\n",
            "Epoch 00065: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 52ms/step - loss: 0.0098 - val_loss: 0.0015\n",
            "Epoch 66/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0091\n",
            "Epoch 00066: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0090 - val_loss: 0.0018\n",
            "Epoch 67/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0099\n",
            "Epoch 00067: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0099 - val_loss: 0.0083\n",
            "Epoch 68/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0093\n",
            "Epoch 00068: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0092 - val_loss: 0.0011\n",
            "Epoch 69/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0094\n",
            "Epoch 00069: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 57ms/step - loss: 0.0094 - val_loss: 0.0022\n",
            "Epoch 70/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0089\n",
            "Epoch 00070: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0089 - val_loss: 0.0013\n",
            "Epoch 71/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0083\n",
            "Epoch 00071: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0083 - val_loss: 0.0036\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0090\n",
            "Epoch 00072: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 57ms/step - loss: 0.0090 - val_loss: 0.0043\n",
            "Epoch 73/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0091\n",
            "Epoch 00073: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0090 - val_loss: 0.0038\n",
            "Epoch 74/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0089\n",
            "Epoch 00074: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0088 - val_loss: 0.0032\n",
            "Epoch 75/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0088\n",
            "Epoch 00075: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0087 - val_loss: 0.0017\n",
            "Epoch 76/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0087\n",
            "Epoch 00076: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0088 - val_loss: 0.0043\n",
            "Epoch 77/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0082\n",
            "Epoch 00077: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 57ms/step - loss: 0.0081 - val_loss: 0.0013\n",
            "Epoch 78/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0086\n",
            "Epoch 00078: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0087 - val_loss: 0.0015\n",
            "Epoch 79/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0085\n",
            "Epoch 00079: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0085 - val_loss: 0.0018\n",
            "Epoch 80/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0081\n",
            "Epoch 00080: val_loss did not improve from 0.00093\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0080 - val_loss: 0.0020\n",
            "Epoch 81/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0079\n",
            "Epoch 00081: val_loss improved from 0.00093 to 0.00090, saving model to weights-btc.hdf5\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0078 - val_loss: 8.9724e-04\n",
            "Epoch 82/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0085\n",
            "Epoch 00082: val_loss did not improve from 0.00090\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0087 - val_loss: 0.0026\n",
            "Epoch 83/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0079\n",
            "Epoch 00083: val_loss improved from 0.00090 to 0.00063, saving model to weights-btc.hdf5\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.0078 - val_loss: 6.2998e-04\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0090\n",
            "Epoch 00084: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0090 - val_loss: 0.0012\n",
            "Epoch 85/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0078\n",
            "Epoch 00085: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 57ms/step - loss: 0.0079 - val_loss: 0.0053\n",
            "Epoch 86/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0077\n",
            "Epoch 00086: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0077 - val_loss: 0.0022\n",
            "Epoch 87/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0080\n",
            "Epoch 00087: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0080 - val_loss: 7.8155e-04\n",
            "Epoch 88/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0066\n",
            "Epoch 00088: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0066 - val_loss: 9.5849e-04\n",
            "Epoch 89/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0074\n",
            "Epoch 00089: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0074 - val_loss: 0.0012\n",
            "Epoch 90/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 00090: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0071 - val_loss: 0.0028\n",
            "Epoch 91/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0082\n",
            "Epoch 00091: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0081 - val_loss: 0.0091\n",
            "Epoch 92/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 00092: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0072 - val_loss: 8.2639e-04\n",
            "Epoch 93/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0083\n",
            "Epoch 00093: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0082 - val_loss: 6.4758e-04\n",
            "Epoch 94/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0077\n",
            "Epoch 00094: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0078 - val_loss: 7.6557e-04\n",
            "Epoch 95/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0068\n",
            "Epoch 00095: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0068 - val_loss: 0.0075\n",
            "Epoch 96/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 00096: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 57ms/step - loss: 0.0071 - val_loss: 0.0029\n",
            "Epoch 97/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 00097: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0072 - val_loss: 0.0019\n",
            "Epoch 98/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0084\n",
            "Epoch 00098: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0084 - val_loss: 0.0170\n",
            "Epoch 99/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0077\n",
            "Epoch 00099: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0076 - val_loss: 0.0036\n",
            "Epoch 100/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0062\n",
            "Epoch 00100: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0062 - val_loss: 0.0017\n",
            "Epoch 101/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0075\n",
            "Epoch 00101: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0075 - val_loss: 0.0010\n",
            "Epoch 102/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0069\n",
            "Epoch 00102: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0069 - val_loss: 9.8238e-04\n",
            "Epoch 103/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0059\n",
            "Epoch 00103: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 57ms/step - loss: 0.0060 - val_loss: 0.0010\n",
            "Epoch 104/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0068\n",
            "Epoch 00104: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0068 - val_loss: 9.9811e-04\n",
            "Epoch 105/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0054\n",
            "Epoch 00105: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0054 - val_loss: 0.0015\n",
            "Epoch 106/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0065\n",
            "Epoch 00106: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0064 - val_loss: 0.0058\n",
            "Epoch 107/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 00107: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0071 - val_loss: 0.0019\n",
            "Epoch 108/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0061\n",
            "Epoch 00108: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 57ms/step - loss: 0.0061 - val_loss: 7.1056e-04\n",
            "Epoch 109/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0062\n",
            "Epoch 00109: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0061 - val_loss: 0.0011\n",
            "Epoch 110/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0074\n",
            "Epoch 00110: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0073 - val_loss: 0.0040\n",
            "Epoch 111/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0062\n",
            "Epoch 00111: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0064 - val_loss: 7.8759e-04\n",
            "Epoch 112/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0065\n",
            "Epoch 00112: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0065 - val_loss: 0.0033\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0069\n",
            "Epoch 00113: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 57ms/step - loss: 0.0069 - val_loss: 7.2030e-04\n",
            "Epoch 114/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0073\n",
            "Epoch 00114: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0073 - val_loss: 0.0019\n",
            "Epoch 115/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0069\n",
            "Epoch 00115: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0070 - val_loss: 0.0050\n",
            "Epoch 116/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0072\n",
            "Epoch 00116: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0072 - val_loss: 6.5932e-04\n",
            "Epoch 117/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0070\n",
            "Epoch 00117: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0070 - val_loss: 0.0015\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0062\n",
            "Epoch 00118: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 57ms/step - loss: 0.0062 - val_loss: 0.0013\n",
            "Epoch 119/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0071\n",
            "Epoch 00119: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 48ms/step - loss: 0.0071 - val_loss: 0.0023\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0070\n",
            "Epoch 00120: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 50ms/step - loss: 0.0070 - val_loss: 8.7628e-04\n",
            "Epoch 121/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0068\n",
            "Epoch 00121: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 49ms/step - loss: 0.0067 - val_loss: 0.0058\n",
            "Epoch 122/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0075\n",
            "Epoch 00122: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0075 - val_loss: 0.0021\n",
            "Epoch 123/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0065\n",
            "Epoch 00123: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0065 - val_loss: 7.3496e-04\n",
            "Epoch 124/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0066\n",
            "Epoch 00124: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0065 - val_loss: 0.0016\n",
            "Epoch 125/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0058\n",
            "Epoch 00125: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 57ms/step - loss: 0.0058 - val_loss: 0.0040\n",
            "Epoch 126/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0064\n",
            "Epoch 00126: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0063 - val_loss: 0.0013\n",
            "Epoch 127/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0060\n",
            "Epoch 00127: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0060 - val_loss: 7.7052e-04\n",
            "Epoch 128/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0065\n",
            "Epoch 00128: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0066 - val_loss: 0.0044\n",
            "Epoch 129/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0066\n",
            "Epoch 00129: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0065 - val_loss: 0.0022\n",
            "Epoch 130/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0081\n",
            "Epoch 00130: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0081 - val_loss: 0.0024\n",
            "Epoch 131/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0058\n",
            "Epoch 00131: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0058 - val_loss: 0.0012\n",
            "Epoch 132/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0062\n",
            "Epoch 00132: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0061 - val_loss: 8.2565e-04\n",
            "Epoch 133/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0069\n",
            "Epoch 00133: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0068 - val_loss: 7.1408e-04\n",
            "Epoch 134/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0055\n",
            "Epoch 00134: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0055 - val_loss: 0.0022\n",
            "Epoch 135/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0060\n",
            "Epoch 00135: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0060 - val_loss: 0.0013\n",
            "Epoch 136/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0078\n",
            "Epoch 00136: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0078 - val_loss: 0.0052\n",
            "Epoch 137/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0066\n",
            "Epoch 00137: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0071 - val_loss: 0.0078\n",
            "Epoch 138/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0079\n",
            "Epoch 00138: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0078 - val_loss: 0.0024\n",
            "Epoch 139/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0062\n",
            "Epoch 00139: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0062 - val_loss: 0.0020\n",
            "Epoch 140/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0065\n",
            "Epoch 00140: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0065 - val_loss: 0.0028\n",
            "Epoch 141/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0069\n",
            "Epoch 00141: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.0069 - val_loss: 0.0037\n",
            "Epoch 142/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0061\n",
            "Epoch 00142: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0060 - val_loss: 0.0013\n",
            "Epoch 143/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0063\n",
            "Epoch 00143: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0064 - val_loss: 0.0028\n",
            "Epoch 144/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0065\n",
            "Epoch 00144: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.0067 - val_loss: 0.0040\n",
            "Epoch 145/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0075\n",
            "Epoch 00145: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0074 - val_loss: 9.0695e-04\n",
            "Epoch 146/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0070\n",
            "Epoch 00146: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.0070 - val_loss: 0.0034\n",
            "Epoch 147/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0072\n",
            "Epoch 00147: val_loss did not improve from 0.00063\n",
            "32/32 [==============================] - 2s 58ms/step - loss: 0.0072 - val_loss: 0.0103\n",
            "Epoch 148/200\n",
            "18/32 [===============>..............] - ETA: 0s - loss: 0.0091"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnqCiFkNPD4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15,7))\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.legend([\"train_loss\", \"val_loss\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQmk7kfYYKCk",
        "colab_type": "text"
      },
      "source": [
        "#**TEST PREDICTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AddFpn3ERBDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(filepath)\n",
        "\n",
        "descale = (max_-min_)+min_\n",
        "\n",
        "predict_close=[]\n",
        "predict_close=np.reshape(model.predict(X_test) * descale,(1,-1))\n",
        "predict_close=predict_close[0]\n",
        "performance=pd.DataFrame([predict_close, y_test * descale])\n",
        "performance=performance.T\n",
        "performance.columns=['Predicted','Actual']\n",
        "performance.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBLqd_avQ4Oq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Spread = []\n",
        "Spread = performance.Actual - performance.Predicted\n",
        "\n",
        "plt.figure(figsize=(15,7))\n",
        "plt.plot(performance.Predicted,c='y')\n",
        "plt.plot(performance.Actual,c='b')\n",
        "plt.legend(['Predicted_Close','Actual_Close'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTZkk9FCYd9E",
        "colab_type": "text"
      },
      "source": [
        "#**MEASURE MODEL PERFORMANCE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWzJHu8DQ7wX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TEST FOR PROFIT\n",
        "\n",
        "# TODO: This part of the cold is recycled from old code, so naming conventions must be matched\n",
        "\n",
        "# If next predicted price is higher than actual price, buy.\n",
        "# Otherwise, stay out of the market.\n",
        "\n",
        "current_position = 0\n",
        "\n",
        "sample = performance\n",
        "\n",
        "for idx in range(0, 59):\n",
        "  if sample.loc[idx, 'Actual'] < sample.loc[idx+1, 'Predicted']:\n",
        "    current_position = 1\n",
        "  else:\n",
        "    current_position = 0\n",
        "  sample.loc[idx,'Position'] = current_position\n",
        "  sample.loc[idx, 'Profit'] = current_position*(sample.loc[idx+1, 'Actual'] - sample.loc[idx, 'Actual'])\n",
        "  \n",
        "#sample.profit.plot()\n",
        "#plt.axhline(y=0, color='red')\n",
        "\n",
        "plt.title(\"Profit per day over history\",fontsize=20)\n",
        "sample['Wealth'] = sample['Profit'].cumsum()\n",
        "sample.Wealth.plot()\n",
        "plt.axhline(y=0, color='red')\n",
        "plt.title(\"Accumulated profit in {:.0f} days: {:.2f} ({:.2f}%)\".format(\n",
        "    len(sample.index),\n",
        "    sample.loc[sample.index[-3], 'Wealth'],\n",
        "    sample.loc[sample.index[-3], 'Wealth']/sample.loc[sample.index[0], 'Actual']*100),\n",
        "    fontsize=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3IbAPM1RMXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Market profit: {:.2f}%\".format((sample.loc[sample.index[-3], 'Actual']/sample.loc[0, 'Actual']-1)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztb01Zpppudy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize Model vs Buy&Hold side by side\n",
        "\n",
        "sample['TotalWealth'] = sample['Wealth'] + sample.Actual[0]\n",
        "sample.TotalWealth.plot(color=\"blue\")\n",
        "plt.axhline(y=sample.Actual[0], color='red')\n",
        "sample.Actual.plot(color='yellow')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sKCS30Rpvml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}